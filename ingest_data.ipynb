{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import constants\n",
    "\n",
    "from langchain.text_splitter import Language\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.document_loaders import GitLoader\n",
    "from langchain.document_loaders import NotebookLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = constants.APIKEY\n",
    "\n",
    "# Paths to repos to ingest\n",
    "aeon_analysis = \"path/to/aeon_analysis\"\n",
    "aeon_mecha = \"path/to/aeon_mecha\"\n",
    "\n",
    "# Define splitters:\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.PYTHON, \n",
    "                                                               chunk_size=2000, \n",
    "                                                               chunk_overlap=200)\n",
    "markdown_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.MARKDOWN,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t chunk_size = 500, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t chunk_overlap = 0)\n",
    "\n",
    "# Ingest Aeon Mecha\n",
    "# We load the py code using LanguageParser, which will:\n",
    "# Keep top-level functions and classes together (into a single document)\n",
    "# Put remaining code into a separate document\n",
    "# Retains metadata about where each split comes from\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    aeon_mecha +'/aeon', # Can remove if you want to load all the python files from the repo\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".py\"],\n",
    "    parser=LanguageParser(language=Language.PYTHON)\n",
    ")\n",
    "documents = loader.load()\n",
    "texts = python_splitter.split_documents(documents)\n",
    "\n",
    "loader = GitLoader(\n",
    "    repo_path=aeon_mecha,\n",
    "    file_filter=lambda file_path: file_path.endswith(\".md\"),\n",
    ") # You can specify a branch if you want\n",
    "documents = loader.load()\n",
    "texts.extend(markdown_splitter.split_documents(documents))\n",
    "\n",
    "# # FOR SOME REASON THIS IS GETTING STUCK ON LOADER.LOAD...\n",
    "# for root, dirs, files in os.walk(aeon_mecha):\n",
    "#     for file in files:\n",
    "#         if file.endswith(\".md\"):\n",
    "#             path = os.path.abspath(os.path.join(root, file))\n",
    "#             print(path)\n",
    "#             loader = UnstructuredMarkdownLoader(path)\n",
    "#             documents = loader.load()\n",
    "#             texts.extend(markdown_splitter.split_documents(documents))\n",
    "\n",
    "# Ingest Aeon Analysis\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    aeon_analysis +'/aeon_analysis', # Can remove if you want to load all the python files from the repo\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".py\"],\n",
    "    parser=LanguageParser(language=Language.PYTHON)\n",
    ")\n",
    "documents = loader.load()\n",
    "texts.extend(python_splitter.split_documents(documents))\n",
    "\n",
    "for root, dirs, files in os.walk(aeon_analysis):\n",
    "    for file in files:\n",
    "        if file.endswith(\".ipynb\"):\n",
    "            path = os.path.abspath(os.path.join(root, file))\n",
    "            loader = NotebookLoader(path)\n",
    "            documents = loader.load()\n",
    "            texts.extend(python_splitter.split_documents(documents))\n",
    "\n",
    "# Chroma\n",
    "vectorstore = Chroma.from_documents(texts, OpenAIEmbeddings(), persist_directory='chroma_vectorstore', collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "\n",
    "# FAISS\n",
    "# vectorstore = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
    "# with open(\"vectorstore.pkl\", \"wb\") as f:\n",
    "# \tpickle.dump(vectorstore, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
